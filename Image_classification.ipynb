{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAnfKACT4yM0",
        "outputId": "719b56dd-ef9d-455b-838c-c60f2990239e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqO-2oqu6uAA",
        "outputId": "e89e1db0-cdfa-47df-bfaa-c37c5051f024"
      },
      "source": [
        "%%writefile requirements.txt\n",
        "\n",
        "tensorflow\n",
        "keras\n",
        "split-folders\n",
        "tqdm\n",
        "termcolor\n",
        "colorama\n",
        "sklearn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HwpTXqx49cY",
        "outputId": "980eeeb3-59db-47cb-d89e-da8a8c654cac"
      },
      "source": [
        "%%writefile iqc_train_model.py\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import splitfolders\n",
        "from tqdm import trange\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, AveragePooling2D, BatchNormalization\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "WD = os.getcwd()\n",
        "CLASSES = ['bad', 'average', 'good']\n",
        "\n",
        "def create_data():\n",
        "    # creating a new folder for every class\n",
        "    if not os.path.exists('data'):\n",
        "        os.mkdir('data')\n",
        "    for c in CLASSES:\n",
        "        if not os.path.exists(os.path.join('data', c)):\n",
        "            os.mkdir(os.path.join('data', c))\n",
        "\n",
        "    # saving all scores in a list\n",
        "    scores = []\n",
        "    with open('drive/MyDrive/scores.txt', 'r') as sc:\n",
        "        for record in sc.readlines():\n",
        "            scores.append(record.split(',')[1].rstrip('\\n'))\n",
        "\n",
        "    # copying the image to the corresponding class folder based on score\n",
        "    images = len(os.listdir('drive/MyDrive/frames'))\n",
        "    if len(os.listdir('data/good')) == 0 and len(os.listdir('data/average')) == 0 and len(os.listdir('data/bad')) == 0:\n",
        "        for image in trange(images):\n",
        "            shutil.copy(f'drive/MyDrive/frames/{image}.png', f'data/{scores[image]}')\n",
        "\n",
        "    # splitting into train, test && validation\n",
        "    splitfolders.ratio('data', output=\"split_data\", seed=1337, ratio=(.8, .1, .1))\n",
        "\n",
        "def preprocess_data():\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "\n",
        "    # resize, grayscale, define labels\n",
        "    for c in CLASSES:\n",
        "        for img in os.listdir(f'split_data/train/{c}'):\n",
        "            train_images.append(img_to_array(load_img(f'split_data/train/{c}/' + img, target_size=(256, 256)))[:, :, 0])\n",
        "            train_labels.append(c)\n",
        "\n",
        "    for c in CLASSES:\n",
        "        for img in os.listdir(f'split_data/test/{c}'):\n",
        "            test_images.append(img_to_array(load_img(f'split_data/test/{c}/' + img, target_size=(256, 256)))[:, :, 0])\n",
        "            test_labels.append(c)\n",
        "\n",
        "    # reshape, normalize, one color channel\n",
        "    train_images = np.array(train_images).reshape(len(train_images), 256, 256, 1) / 255\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_images = np.array(test_images).reshape(len(test_images), 256, 256, 1) / 255\n",
        "    test_labels = np.array(test_labels)\n",
        "\n",
        "    # convert train labels to numerical\n",
        "    for i in range(len(train_labels)):\n",
        "        train_labels[i] = CLASSES.index(train_labels[i])\n",
        "    train_labels = train_labels.astype('int32')\n",
        "\n",
        "    # convert test labels to numerical\n",
        "    for i in range(len(test_labels)):\n",
        "        test_labels[i] = CLASSES.index(test_labels[i])\n",
        "    test_labels = test_labels.astype('int32')\n",
        "\n",
        "    train_images, train_labels = shuffle(train_images, train_labels)\n",
        "    test_images, test_labels = shuffle(test_images, test_labels)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "def build_model(train_images, train_labels, test_images, test_labels):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(256, 256, 1)))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'], optimizer='adam')\n",
        "    model.fit(train_images, train_labels, epochs=8, batch_size=128)\n",
        "\n",
        "    model.summary()\n",
        "    model.evaluate(test_images, test_labels, batch_size=64)\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('This might take a while..')\n",
        "\n",
        "    # organize images & split folders\n",
        "    create_data()\n",
        "    # preprocess the images\n",
        "    X_train, y_train, X_test, y_test = preprocess_data()\n",
        "    # build the model and train it\n",
        "    \n",
        "    print('Training..')\n",
        "    model = build_model(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # save model\n",
        "    filepath = './image_quality_classifier'\n",
        "    keras.models.save_model(model, filepath)\n",
        "    print('Model saved!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting iqc_train_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezpfXiMb5_aS",
        "outputId": "0dcfdf16-0056-41fb-9f33-f3ae59616ac3"
      },
      "source": [
        "%%writefile iqc_predict.py\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "from termcolor import *\n",
        "import colorama\n",
        "colorama.init()\n",
        "\n",
        "import numpy as np\n",
        "import splitfolders\n",
        "from tqdm import trange\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow import keras\n",
        "\n",
        "def arg_parser():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"-i\", \"--image\", required=True, help=\"input an image\")\n",
        "\n",
        "    return vars(ap.parse_args())\n",
        "\n",
        "def load_model():\n",
        "    filepath = 'image_quality_classifier'\n",
        "    model = keras.models.load_model(filepath, compile=True)\n",
        "    return model\n",
        "\n",
        "def preprocess_input(img):\n",
        "    sample = np.array(img_to_array(load_img(img, target_size=(256, 256)))[:, :, 0])\n",
        "    sample = sample.reshape(1, sample.shape[0], sample.shape[1], 1)\n",
        "    sample /= 255\n",
        "    return sample\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    output_quality = {0: 'bad', 1: 'average', 2:'good'}\n",
        "    model = load_model()\n",
        "    args = arg_parser()\n",
        "    img = preprocess_input(args['image'])\n",
        "    predictions = model.predict(img)\n",
        "    print('Image quality:')\n",
        "    if np.argmax(predictions, axis=1)[0] == 0:\n",
        "        cprint(output_quality[np.argmax(predictions, axis=1)[0]], 'red')\n",
        "    elif np.argmax(predictions, axis=1)[0] == 1:\n",
        "        cprint(output_quality[np.argmax(predictions, axis=1)[0]], 'yellow')\n",
        "    elif np.argmax(predictions, axis=1)[0] == 2:\n",
        "        cprint(output_quality[np.argmax(predictions, axis=1)[0]], 'green')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting iqc_predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31lPrYg86r8x"
      },
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yn0ccO76bVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba9229b-01b3-47d6-b594-a50e25b40699"
      },
      "source": [
        "!python3 iqc_train_model.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This might take a while..\n",
            "100% 1002/1002 [04:33<00:00,  3.67it/s]\n",
            "Copying files: 1002 files [00:02, 428.59 files/s]\n",
            "Training..\n",
            "2021-11-21 22:54:44.971474: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Epoch 1/8\n",
            "7/7 [==============================] - 36s 566ms/step - loss: 4.3695 - accuracy: 0.3333\n",
            "Epoch 2/8\n",
            "7/7 [==============================] - 3s 415ms/step - loss: 0.9489 - accuracy: 0.3308\n",
            "Epoch 3/8\n",
            "7/7 [==============================] - 3s 416ms/step - loss: 0.6968 - accuracy: 0.5768\n",
            "Epoch 4/8\n",
            "7/7 [==============================] - 3s 416ms/step - loss: 0.5035 - accuracy: 0.6667\n",
            "Epoch 5/8\n",
            "7/7 [==============================] - 3s 416ms/step - loss: 0.4033 - accuracy: 0.6679\n",
            "Epoch 6/8\n",
            "7/7 [==============================] - 3s 415ms/step - loss: 0.3578 - accuracy: 0.7653\n",
            "Epoch 7/8\n",
            "7/7 [==============================] - 3s 417ms/step - loss: 0.3183 - accuracy: 0.9201\n",
            "Epoch 8/8\n",
            "7/7 [==============================] - 3s 416ms/step - loss: 0.1485 - accuracy: 1.0000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 64)      640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 32)      18464     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 123008)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               31490304  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,510,179\n",
            "Trainable params: 31,510,179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2/2 [==============================] - 2s 617ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "2021-11-21 22:55:45.131408: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqDaOIvkKmXT"
      },
      "source": [
        "Predictions on the 'frames' folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCVxP6Wz7Brc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ba4036-68b9-4dde-98c4-1667a13bf1bb"
      },
      "source": [
        "!python3 iqc_predict.py --image drive/MyDrive/frames/0.png"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-21 22:56:30.306427: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Image quality:\n",
            "\u001b[31mbad\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mANmqBkl7SRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332d8fae-7069-4af7-cee2-6454b5bc78aa"
      },
      "source": [
        "!python3 iqc_predict.py --image drive/MyDrive/frames/6.png"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-21 22:56:37.025739: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Image quality:\n",
            "\u001b[33maverage\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTEeiQmE7OZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ac930f-8a00-4642-ef33-3097679c60b2"
      },
      "source": [
        "!python3 iqc_predict.py --image drive/MyDrive/frames/1.png"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-21 22:56:43.946051: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Image quality:\n",
            "\u001b[32mgood\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7s5gJRaKs6z"
      },
      "source": [
        "Predictions on images in the validation folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MH8irZwKIKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e89f92-9310-4502-de94-d2b2c6250391"
      },
      "source": [
        "!python3 iqc_predict.py --image split_data/val/bad/120.png"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-21 22:56:09.029700: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Image quality:\n",
            "\u001b[31mbad\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwCaOR0m7UQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25da9955-00d6-48b1-e17e-2a0e594c0bbb"
      },
      "source": [
        "!python3 iqc_predict.py --image split_data/val/average/115.png"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-21 22:56:16.116563: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Image quality:\n",
            "\u001b[33maverage\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UDQgrR_KS6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bfc1ecf-a1bb-4e58-b4c4-83bc11cac991"
      },
      "source": [
        "!python3 iqc_predict.py --image split_data/val/good/111.png"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-21 22:56:22.724733: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Image quality:\n",
            "\u001b[32mgood\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ]
}